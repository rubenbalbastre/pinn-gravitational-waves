{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main EMR code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"../../../../../\"\n",
    "utils_path = project_path * \"src/utils/\"\n",
    "\n",
    "output_directory = project_path * \"data/output/case_1/kerr/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Escritorio/TFM/code/01_project`\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:\n",
      "\n",
      "Stacktrace:\n",
      "  [1] _include_from_serialized(pkg::Base.PkgId, path::String, depmods::Vector{Any})\n",
      "    @ Base ./loading.jl:807\n",
      "  [2] _tryrequire_from_serialized(modkey::Base.PkgId, path::String, sourcepath::String, depmods::Vector{Any})\n",
      "    @ Base ./loading.jl:938\n",
      "  [3] _require_search_from_serialized(pkg::Base.PkgId, sourcepath::String, build_id::UInt64)\n",
      "    @ Base ./loading.jl:1028\n",
      "  [4] _require(pkg::Base.PkgId)\n",
      "    @ Base ./loading.jl:1315\n",
      "  [5] _require_prelocked(uuidkey::Base.PkgId)\n",
      "    @ Base ./loading.jl:1200\n",
      "  [6] macro expansion\n",
      "    @ ./loading.jl:1180 [inlined]\n",
      "  [7] macro expansion\n",
      "    @ ./lock.jl:223 [inlined]\n",
      "  [8] require(into::Module, mod::Symbol)\n",
      "    @ Base ./loading.jl:1144\n",
      "  [9] eval\n",
      "    @ ./boot.jl:368 [inlined]\n",
      " [10] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base ./loading.jl:1428\n",
      " [11] #invokelatest#2\n",
      "    @ ./essentials.jl:729 [inlined]\n",
      " [12] invokelatest\n",
      "    @ ./essentials.jl:726 [inlined]\n",
      " [13] (::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:19\n",
      " [14] withpath(f::VSCodeServer.var\"#219#220\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/repl.jl:276\n",
      " [15] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:13\n",
      " [16] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode/extensions/julialang.language-julia-1.79.2/scripts/packages/JSONRPC/src/typed.jl:67\n",
      " [17] serve_notebook(pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; crashreporting_pipename::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.79.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:139\n",
      " [18] top-level scope\n",
      "    @ ~/.vscode/extensions/julialang.language-julia-1.79.2/scripts/notebook/notebook.jl:35"
     ]
    }
   ],
   "source": [
    "\n",
    "cd(@__DIR__)\n",
    "using Pkg; Pkg.activate(project_path); \n",
    "Pkg.instantiate();\n",
    "using OrdinaryDiffEq;\n",
    "using Optim;\n",
    "using LineSearches;\n",
    "using DiffEqFlux;\n",
    "using DiffEqSensitivity;\n",
    "using Plots;\n",
    "using DataFrames;\n",
    "using CSV;\n",
    "using Statistics;\n",
    "using Flux;\n",
    "using Random;\n",
    "import BSON: @save, @load\n",
    "# gr(); # specify backend for plotting\n",
    "\n",
    "include(utils_path * \"utils.jl\")\n",
    "import_project_utils(utils_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: Random not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Random not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Escritorio/TFM/code/01_project/src/processing/experiments/kerr/case_1/EMR_kerr_train.ipynb:3"
     ]
    }
   ],
   "source": [
    "# specify random seed\n",
    "seed = 1234;\n",
    "Random.seed!(seed)\n",
    "\n",
    "# script conditions\n",
    "show_plots = true\n",
    "save_plots_gif = true\n",
    "save_data = false\n",
    "\n",
    "# paths\n",
    "test_name = \"test_1_cos/\"\n",
    "model_name = \"test_1_cos/\" #\"encoder/\" #\n",
    "\n",
    "output_dir = output_directory* \"models/\" * test_name\n",
    "solutions_dir = output_dir * \"solutions/\"\n",
    "metrics_dir = output_directory * \"metrics/\"\n",
    "img_dir = output_dir * \"train_img_for_gif/\"\n",
    "list_directories = (output_dir, solutions_dir, metrics_dir, img_dir)\n",
    "create_directories(list_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: nn_model_case1 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: nn_model_case1 not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Escritorio/TFM/code/01_project/src/processing/experiments/kerr/case_1/EMR_kerr_train.ipynb:2"
     ]
    }
   ],
   "source": [
    "# Define neural network model\n",
    "NN, NN_params, chain, re = nn_model_case1(model_name);\n",
    "\n",
    "# --------------------------------------\n",
    "\n",
    "datasize = 250\n",
    "mass_ratio = 0.0\n",
    "dt = 100.0\n",
    "\n",
    "# TRAIN waveform parameters\n",
    "\n",
    "χ₀ = Float64(pi); \n",
    "ϕ₀ = Float64(0.0); \n",
    "# p_space=Float64.([100,50,70,90]); \n",
    "p_space = Float64.([100])\n",
    "M=Float64(1.0); \n",
    "# e_space = Float64.([0.2,0.5,0.8])\n",
    "e_space = Float64.([0.5])\n",
    "tspan_train = (0, 6.0f4)\n",
    "a = 0.5\n",
    "\n",
    "println(\"Train dataset creation\")\n",
    "train_info = [];\n",
    "for e in e_space \n",
    "    for p in p_space\n",
    "        train_info_i = get_problem_information_EMR_kerr(χ₀, ϕ₀, p, M, e, a, mass_ratio, tspan_train, datasize, dt);\n",
    "        push!(train_info, train_info_i)\n",
    "    end\n",
    "end\n",
    "\n",
    "# TEST waveform parameters\n",
    "\n",
    "χ₀ = Float64(pi); \n",
    "ϕ₀ = Float64(0.0); \n",
    "p=Float64(80.0); \n",
    "M=Float64(1.0); \n",
    "e = Float64(0.4)\n",
    "tspan_test = (tspan_train[2]*48, tspan_train[2]*50)\n",
    "a=0.3\n",
    "\n",
    "println(\"Test dataset creation\")\n",
    "test_info = [get_problem_information_EMR_kerr(χ₀, ϕ₀, p, M, e, a, mass_ratio, tspan_test, datasize, dt)];\n",
    "\n",
    "# put data in arrays\n",
    "println(\"Processing datasets\")\n",
    "datasets = Dict(\"train\" => train_info, \"test\" => test_info)\n",
    "processed_data = process_datasets(datasets);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why wave starts from a so high values. I understand that is due to numerical issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating zero training steps image\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: processed_data not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: processed_data not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Escritorio/TFM/code/01_project/src/processing/experiments/kerr/case_1/EMR_kerr_train.ipynb:5"
     ]
    }
   ],
   "source": [
    "# zero training image\n",
    "\n",
    "println(\"Generating zero training steps image\")\n",
    "\n",
    "example = processed_data[\"train\"][1]\n",
    "zero_training_solution = Array(solve(\n",
    "    example[\"nn_problem\"],\n",
    "    RK4(), \n",
    "    saveat = example[\"tsteps\"], \n",
    "    dt = dt, \n",
    "    adaptive=false\n",
    "))\n",
    "pred_waveform, _ = compute_waveform(example[\"dt_data\"], zero_training_solution, example[\"q\"], example[\"M\"], example[\"model_params\"])\n",
    "zero_training_plt = train_plot(example[\"tsteps\"], example[\"true_waveform\"], pred_waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @layout not defined\nin expression starting at /home/rubenbalbastre/Escritorio/TFM/code/01_project/src/processing/experiments/kerr/case_1/EMR_kerr_train.ipynb:22",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @layout not defined\n",
      "in expression starting at /home/rubenbalbastre/Escritorio/TFM/code/01_project/src/processing/experiments/kerr/case_1/EMR_kerr_train.ipynb:22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_metrics = []\n",
    "test_metrics = []\n",
    "plot_list = []\n",
    "\n",
    "callback_EMR(θ::Vector{Float64}, train_loss::Float64, agregated_metrics::Dict{String, Float64}, train_loss_information::Dict, test_loss_information::Dict; show_plots::Bool = show_plots, save_plots_gif::Bool=save_plots_gif) = begin\n",
    "\n",
    "    # add losses\n",
    "    push!(train_losses, agregated_metrics[\"train_loss\"])\n",
    "    push!(test_losses, agregated_metrics[\"test_loss\"])\n",
    "    push!(train_metrics, agregated_metrics[\"train_metric\"])\n",
    "    push!(test_metrics, agregated_metrics[\"test_metric\"])\n",
    "\n",
    "    # train waveform\n",
    "    plt1 = train_plot(train_loss_information[\"tsteps\"], train_loss_information[\"true_waveform\"], train_loss_information[\"pred_waveform\"])\n",
    "\n",
    "    # test waveform\n",
    "    plt2 = test_plot(test_loss_information[\"tsteps\"], test_loss_information[\"tsteps\"], test_loss_information[\"true_waveform\"], test_loss_information[\"pred_waveform\"])\n",
    "\n",
    "    l = @layout [a; b]\n",
    "    plt = plot(plt1, plt2, layout=l)\n",
    "    if save_plots_gif\n",
    "        push!(plot_list, plt)\n",
    "    end\n",
    "\n",
    "    return false\n",
    "end\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "\n",
    "# Train\n",
    "loss_f(p) = loss_function_case1(p, processed_data=processed_data, batch_number=2)\n",
    "\n",
    "# optimisers \n",
    "# Flux.Optimise.Descent(0.001)\n",
    "# Flux.Optimise.ADAM(5e-5, (0.9, 0.999)), \n",
    "# Flux.Optimise.RADAM(1e-4, (0.9, 0.999)),\n",
    "# BFGS(initial_stepnorm=0.01, linesearch = LineSearches.BackTracking()),\n",
    "\n",
    "println(\"Start Training\")\n",
    "res = DiffEqFlux.sciml_train(\n",
    "    loss_f, \n",
    "    NN_params,\n",
    "    BFGS(initial_stepnorm=0.01, linesearch = LineSearches.BackTracking()),\n",
    "    cb=callback_EMR, \n",
    "    maxiters = 100\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0"
     ]
    },
    {
     "ename": "BoundsError",
     "evalue": "BoundsError: attempt to access 0-element Vector{Any} at index [0]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 0-element Vector{Any} at index [0]\n",
      "\n",
      "Stacktrace:\n",
      " [1] getindex(A::Vector{Any}, i1::Int64)\n",
      "   @ Base ./array.jl:924\n",
      " [2] top-level scope\n",
      "   @ ~/Escritorio/TFM/code/01_project/src/processing/experiments/kerr/case_1/EMR_kerr_train.ipynb:2"
     ]
    }
   ],
   "source": [
    "print(length(plot_list))\n",
    "plot(plot_list[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"min test loss \", minimum(test_losses))\n",
    "plot(train_losses, label=\"train\")\n",
    "plot!(test_losses, label=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save flux chain models as bson files. To do so, we must save chain model with its parameters\n",
    "Flux.loadparams!(chain, Flux.params(re(res.minimizer)))\n",
    "@save solutions_dir*\"model_chiphi.bson\" chain\n",
    "\n",
    "# save losses\n",
    "losses_df = DataFrame(\n",
    "    epochs = range(1, length(train_losses)),\n",
    "    test_name=test_name,\n",
    "    train_loss = train_losses,\n",
    "    test_loss = test_losses,\n",
    "    train_metric = train_metrics,\n",
    "    test_metric = test_metrics,\n",
    ")\n",
    "\n",
    "if ! isfile(metrics_dir*\"losses.csv\")\n",
    "    CSV.write(metrics_dir*\"losses.csv\", losses_df)\n",
    "else\n",
    "    x = DataFrame(CSV.File(metrics_dir*\"losses.csv\", types=Dict(\"test_name\" => String31)))\n",
    "    append!(x, losses_df)\n",
    "    CSV.write(metrics_dir*\"losses.csv\", x)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data\n",
    "    savefig(zero_training_plt, img_dir*\"0_train_img.pdf\")\n",
    "    savefig(zero_training_plt, img_dir*\"0_train_img.png\")\n",
    "    println(\"Save train images\")\n",
    "    # save plots\n",
    "    for (ind, img) in enumerate(plot_list)\n",
    "        savefig(img, img_dir*string(ind)*\"_train_img.pdf\")\n",
    "        savefig(img, img_dir*string(ind)*\"_train_img.png\")\n",
    "        if ind == length(plot_list)\n",
    "            savefig(img, output_dir*\"prediction_plot.pdf\")\n",
    "            savefig(img, output_dir*\"prediction_plot.png\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
