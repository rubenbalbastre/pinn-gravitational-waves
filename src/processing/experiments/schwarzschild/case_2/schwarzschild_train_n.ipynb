{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2 Experiments: equal mass BBH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"../../../../../\"\n",
    "utils_path = project_path * \"src/utils/\"\n",
    "\n",
    "data_path = project_path * \"data/input/case_2/\";\n",
    "output_directory = project_path * \"data/output/case_2/schwarzschild/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Escritorio/TFM/code/01_project`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cd(@__DIR__)\n",
    "using Pkg; Pkg.activate(project_path); \n",
    "Pkg.instantiate();\n",
    "\n",
    "using OrdinaryDiffEq;\n",
    "using Optim;\n",
    "using DiffEqSensitivity;\n",
    "using Plots;\n",
    "using Flux;\n",
    "\n",
    "\n",
    "import Statistics: mean, sqrt\n",
    "import CSV: CSV\n",
    "import DataFrames: DataFrame, select, filter\n",
    "import DiffEqFlux: sciml_train\n",
    "import Random: seed!\n",
    "import LineSearches: BackTracking\n",
    "import DelimitedFiles: readdlm\n",
    "import BSON: @save, @load\n",
    "# gr(); # specify backend for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "include(utils_path * \"utils.jl\")\n",
    "import_project_utils(utils_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify random seed\n",
    "seed = 1234;\n",
    "seed!(seed)\n",
    "\n",
    "# script conditions\n",
    "show_plots = false\n",
    "save_plots_gif = false\n",
    "save_data = true\n",
    "\n",
    "# paths\n",
    "test_name = \"test_1_cos/\"\n",
    "model_name = \"test_1_cos/\"\n",
    "\n",
    "output_dir = output_directory* \"models/\" * test_name\n",
    "solutions_dir = output_dir * \"solutions/\"\n",
    "metrics_dir = output_directory * \"metrics/\"\n",
    "img_dir = output_dir * \"train_img_for_gif/\"\n",
    "list_directories = (output_dir, solutions_dir, metrics_dir, img_dir)\n",
    "create_directories(list_directories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load SXS Dataset\n",
      "Importing data: SXS:BBH:0211\n",
      "Importing data: SXS:BBH:0217\n"
     ]
    }
   ],
   "source": [
    "# time range\n",
    "datasize = 1500\n",
    "dt = 10.0\n",
    "\n",
    "# Load SXS Dataset\n",
    "wave_ids = [\n",
    "    \"SXS:BBH:0211\",\n",
    "    \"SXS:BBH:0217\"\n",
    "]\n",
    "\n",
    "println(\"Load SXS Dataset\")\n",
    "dataset = load_sxs_data(wave_ids, data_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining model\n"
     ]
    }
   ],
   "source": [
    "println(\"Defining model\")\n",
    "n_neurons = 32\n",
    "nn_output = nn_model_case2(model_name, n_neurons, tanh)\n",
    "global NN_params\n",
    "NN_params, NN_chiphi, NN_chiphi_params, NN_pe, NN_pe_params, chain_phichi, chain_pe, re_chiphi, re_pe = nn_output\n",
    "l1 = length(NN_chiphi_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = add_neural_network_problem_to_dataset(dataset, nn_output);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-training plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching compute_waveform(::Float64, ::Matrix{Float32}, ::Float64, ::Dict{String, Float64})\nClosest candidates are:\n  compute_waveform(::Any, ::Any, ::Any, ::Any, !Matched::Any) at ~/Escritorio/TFM/code/01_project/src/utils/orbital_mechanics/orbital_mechanics_utils.jl:169",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching compute_waveform(::Float64, ::Matrix{Float32}, ::Float64, ::Dict{String, Float64})\n",
      "Closest candidates are:\n",
      "  compute_waveform(::Any, ::Any, ::Any, ::Any, !Matched::Any) at ~/Escritorio/TFM/code/01_project/src/utils/orbital_mechanics/orbital_mechanics_utils.jl:169\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Escritorio/TFM/code/01_project/src/processing/experiments/schwarzschild/case_2/schwarzschild_train_n.ipynb:3"
     ]
    }
   ],
   "source": [
    "example = dataset[wave_ids[1]]\n",
    "neural_network_solution = Array(solve(example[\"nn_problem\"], RK4(), u0 = example[\"u0\"], p = NN_params, saveat = example[\"tsteps\"], dt = dt, adaptive=false))\n",
    "pred_waveform_real_train, pred_waveform_imag_train = compute_waveform(\n",
    "    example[\"dt_data\"], neural_network_solution, example[\"q\"], example[\"model_params\"]\n",
    ")\n",
    "plt1 = plot(\n",
    "    example[\"tsteps\"], example[\"true_waveform\"], \n",
    "    markershape=:none, markeralpha = 0.25, \n",
    "    linewidth = 2, alpha = 0.5, label=\"wform data (Re)\", \n",
    "    legend_position=:topleft, title= \"Train progress \"*wave_ids[1], \n",
    "    titlefontsize = 8, legend_font_pointsize = 6\n",
    ")\n",
    "plot!(\n",
    "    plt1, example[\"tsteps\"], pred_waveform_real_train, \n",
    "    markershape=:none, markeralpha = 0.25,\n",
    "    linewidth = 2, alpha = 0.5, label=\"Waveform NN (Re)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_losses = []\n",
    "train_losses_complete = []\n",
    "train_metrics = []\n",
    "train_metrics_complete = []\n",
    "test_losses = []\n",
    "test_metrics = []\n",
    "\n",
    "callback(θ, train_loss, metrics, train_results_i, train_results_i_complete, test_results_i; show_plots = show_plots, save_plots_gif=save_plots_gif) = begin\n",
    "\n",
    "    # list to save plots -> make a gif to project presentation\n",
    "    if length(train_losses) == 0\n",
    "        global plot_list = []\n",
    "    end\n",
    "\n",
    "    # unpackage training results\n",
    "    N = length(train_results_i[\"pred_waveform\"])\n",
    "\n",
    "    # add losses\n",
    "    push!(train_losses, metrics[\"train_loss\"])\n",
    "    push!(train_losses_complete, metrics[\"train_loss_complete\"])\n",
    "    push!(test_losses, metrics[\"test_loss\"])\n",
    "\n",
    "    # add metrics\n",
    "    push!(train_metrics, metrics[\"train_metric\"])\n",
    "    push!(train_metrics_complete, metrics[\"train_metric_complete\"])\n",
    "    push!(test_metrics, metrics[\"test_metric\"])\n",
    "\n",
    "    if save_data\n",
    "\n",
    "        # train waveform\n",
    "        plt1 = plot(\n",
    "            train_results_i_complete[\"tsteps\"], train_results_i_complete[\"true_waveform\"], \n",
    "            markershape=:none, label=\"wform data (Re)\", \n",
    "            legend_position=:topleft, title= \"Train progress: \" * train_results_i_complete[\"wave_id\"]\n",
    "        )\n",
    "        plot!(\n",
    "            plt1, train_results_i_complete[\"tsteps\"], train_results_i_complete[\"pred_waveform\"], \n",
    "            markershape=:none, label=\"wform NN (Re)\", legend_position=:topleft, \n",
    "            title= \"Train progress: \" * train_results_i_complete[\"wave_id\"]\n",
    "        )\n",
    "        plot!(\n",
    "            plt1, train_results_i_complete[\"tsteps\"][1:N], train_results_i_complete[\"pred_waveform\"][1:N], \n",
    "            markershape=:none, label=\"wform NN (Re)\"\n",
    "        )\n",
    "\n",
    "        # test waveform\n",
    "        plt12 = plot(\n",
    "            test_results_i[\"tsteps\"], test_results_i[\"pred_waveform\"], \n",
    "            markershape=:none, label=\"wform data (Re)\", legend=:topleft, \n",
    "            title= \"Test predictions: \" * test_results_i[\"wave_id\"]\n",
    "        )\n",
    "        plot!(\n",
    "            plt12, test_results_i[\"tsteps\"], test_results_i[\"pred_waveform\"], \n",
    "            markershape=:none, label=\"wform NN (Re)\"\n",
    "        )\n",
    "\n",
    "        # p, e train\n",
    "        p = train_results_i[\"pred_solution\"][3,:]\n",
    "        e = train_results_i[\"pred_solution\"][4,:]\n",
    "        plt3 = plot(train_results_i[\"tsteps\"], p, linewidth = 2, alpha = 0.5, label=\"p\", legend=:best, title=\"Train \" * train_results_i_complete[\"wave_id\"])\n",
    "        plot!(twinx(), train_results_i[\"tsteps\"], e, linewidth = 2, color=:red, alpha = 0.5, label=\"e\", legend=:topleft)\n",
    "\n",
    "        # p,e test\n",
    "        p = test_results_i[\"pred_solution\"][3,:]\n",
    "        e = test_results_i[\"pred_solution\"][4,:]\n",
    "        plt4 = plot(test_results_i[\"tsteps\"], p, linewidth = 2, alpha = 0.5, label=\"p\", legend=:best, title=\"Test \" * test_results_i[\"wave_id\"])\n",
    "        plot!(twinx(), test_results_i[\"tsteps\"], e, linewidth = 2, color=:red, alpha = 0.5, label=\"e\", legend=:topleft)\n",
    "\n",
    "        # losses plot\n",
    "        plt5 = plot(train_losses_complete, label=\"train\", title=\"Loss functions\", xlabel=\"Epochs\")\n",
    "        plot!(plt5, train_losses, label=\"train cost function\")\n",
    "        plot!(plt5, test_losses, label=\"test\")\n",
    "\n",
    "        # save plots\n",
    "        l = @layout [[a; b] [a; b] a{0.3w}]\n",
    "        plt = plot(plt1, plt12, plt3, plt4, plt5, layout=l, size=(2000, 900))\n",
    "        if save_plots_gif\n",
    "            push!(plot_list, plt)\n",
    "        end\n",
    "        if show_plots\n",
    "            display(plot(plt))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Tell sciml_train to not halt the optimization. If return true, then optimization stops.\n",
    "    return false\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dict([key => value for (key, value) in dataset if key != wave_ids[end]]);\n",
    "dataset_test = Dict([key => value for (key, value) in dataset if key == wave_ids[end]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Progressive training...\n",
      "optimization increment :: 40 of 100\n",
      "Training 10.0 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: sciml_train is being deprecated in favor of direct usage of Optimization.jl. Please consult the Optimization.jl documentation for more details. Optimization.jl's PolyOpt solver is the polyalgorithm of sciml_train\n",
      "└ @ DiffEqFlux /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/DiffEqFlux/Em1Aj/src/train.jl:6\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching compute_waveform(::Float64, ::Matrix{Float64}, ::Float64, ::Dict{String, Float64})\nClosest candidates are:\n  compute_waveform(::Any, ::Any, ::Any, ::Any, !Matched::Any) at ~/Escritorio/TFM/code/01_project/src/utils/orbital_mechanics/orbital_mechanics_utils.jl:169",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching compute_waveform(::Float64, ::Matrix{Float64}, ::Float64, ::Dict{String, Float64})\n",
      "Closest candidates are:\n",
      "  compute_waveform(::Any, ::Any, ::Any, ::Any, !Matched::Any) at ~/Escritorio/TFM/code/01_project/src/utils/orbital_mechanics/orbital_mechanics_utils.jl:169\n",
      "\n",
      "Stacktrace:\n",
      "  [1] macro expansion\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0 [inlined]\n",
      "  [2] _pullback(::Zygote.Context{false}, ::typeof(compute_waveform), ::Float64, ::Matrix{Float64}, ::Float64, ::Dict{String, Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:9\n",
      "  [3] _pullback\n",
      "    @ ~/Escritorio/TFM/code/01_project/src/utils/loss_functions/loss_functions.jl:121 [inlined]\n",
      "  [4] _pullback(::Zygote.Context{false}, ::var\"##loss_function_case2_single_waveform#11\", ::Float32, ::Float32, ::Float32, ::Float32, ::Float32, ::Float64, ::Bool, ::Nothing, ::Nothing, ::Nothing, ::Nothing, ::typeof(loss_function_case2_single_waveform), ::Matrix{Float64}, ::Vector{Float64}, ::Float64, ::Vector{Float64}, ::Dict{String, Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0\n",
      "  [5] _pullback\n",
      "    @ ~/Escritorio/TFM/code/01_project/src/utils/loss_functions/loss_functions.jl:108 [inlined]\n",
      "  [6] _pullback(::Zygote.Context{false}, ::typeof(loss_function_case2_single_waveform), ::Matrix{Float64}, ::Vector{Float64}, ::Float64, ::Vector{Float64}, ::Dict{String, Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0\n",
      "  [7] _pullback\n",
      "    @ ~/Escritorio/TFM/code/01_project/src/utils/loss_functions/loss_functions.jl:199 [inlined]\n",
      "  [8] _pullback(::Zygote.Context{false}, ::var\"##loss_function_case2#12\", ::BitVector, ::Dict{String, Dict{String, Any}}, ::Dict{String, Dict{String, Any}}, ::typeof(loss_function_case2), ::Vector{Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0\n",
      "  [9] _pullback\n",
      "    @ ~/Escritorio/TFM/code/01_project/src/utils/loss_functions/loss_functions.jl:176 [inlined]\n",
      " [10] _pullback(::Zygote.Context{false}, ::var\"#loss_function_case2##kw\", ::NamedTuple{(:tsteps_increment_bool, :dataset_train, :dataset_test), Tuple{BitVector, Dict{String, Dict{String, Any}}, Dict{String, Dict{String, Any}}}}, ::typeof(loss_function_case2), ::Vector{Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0\n",
      " [11] _pullback\n",
      "    @ ~/Escritorio/TFM/code/01_project/src/processing/experiments/schwarzschild/case_2/schwarzschild_train_n.ipynb:19 [inlined]\n",
      " [12] _pullback(ctx::Zygote.Context{false}, f::var\"#tmp_loss#192\"{BitVector}, args::Vector{Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0\n",
      " [13] _pullback\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/DiffEqFlux/Em1Aj/src/train.jl:40 [inlined]\n",
      " [14] _pullback(::Zygote.Context{false}, ::DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, ::Vector{Float64}, ::SciMLBase.NullParameters)\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0\n",
      " [15] _apply\n",
      "    @ ./boot.jl:816 [inlined]\n",
      " [16] adjoint\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/lib/lib.jl:203 [inlined]\n",
      " [17] _pullback\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/ZygoteRules/OgCVT/src/adjoint.jl:66 [inlined]\n",
      " [18] _pullback\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/SciMLBase/VdcHg/src/scimlfunctions.jl:3626 [inlined]\n",
      " [19] _pullback(::Zygote.Context{false}, ::OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, ::Vector{Float64}, ::SciMLBase.NullParameters)\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0\n",
      " [20] _apply(::Function, ::Vararg{Any})\n",
      "    @ Core ./boot.jl:816\n",
      " [21] adjoint\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/lib/lib.jl:203 [inlined]\n",
      " [22] _pullback\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/ZygoteRules/OgCVT/src/adjoint.jl:66 [inlined]\n",
      " [23] _pullback\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/Optimization/vFala/src/function/zygote.jl:72 [inlined]\n",
      " [24] _pullback(ctx::Zygote.Context{false}, f::Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}, args::Vector{Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0\n",
      " [25] _apply(::Function, ::Vararg{Any})\n",
      "    @ Core ./boot.jl:816\n",
      " [26] adjoint\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/lib/lib.jl:203 [inlined]\n",
      " [27] _pullback\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/ZygoteRules/OgCVT/src/adjoint.jl:66 [inlined]\n",
      " [28] _pullback\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/Optimization/vFala/src/function/zygote.jl:76 [inlined]\n",
      " [29] _pullback(ctx::Zygote.Context{false}, f::Optimization.var\"#294#303\"{Tuple{}, Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, args::Vector{Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface2.jl:0\n",
      " [30] pullback(f::Function, cx::Zygote.Context{false}, args::Vector{Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface.jl:44\n",
      " [31] pullback\n",
      "    @ ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface.jl:42 [inlined]\n",
      " [32] gradient(f::Function, args::Vector{Float64})\n",
      "    @ Zygote ~/anaconda3/envs/julia/share/julia/packages/Zygote/SuKWp/src/compiler/interface.jl:96\n",
      " [33] (::Optimization.var\"#293#302\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}})(::Vector{Float64}, ::Vector{Float64})\n",
      "    @ Optimization ~/anaconda3/envs/julia/share/julia/packages/Optimization/vFala/src/function/zygote.jl:74\n",
      " [34] (::OptimizationOptimJL.var\"#10#16\"{OptimizationOptimJL.OptimJLOptimizationCache{OptimizationFunction{false, Optimization.AutoZygote, OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.var\"#293#302\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#296#305\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#300#309\", Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}, Nothing, Nothing, Nothing, Nothing, Nothing, BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}, Base.Iterators.Cycle{Tuple{Optimization.NullData}}, Bool, typeof(callback)}, OptimizationOptimJL.var\"#9#15\"{OptimizationOptimJL.OptimJLOptimizationCache{OptimizationFunction{false, Optimization.AutoZygote, OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.var\"#293#302\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#296#305\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#300#309\", Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}, Nothing, Nothing, Nothing, Nothing, Nothing, BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}, Base.Iterators.Cycle{Tuple{Optimization.NullData}}, Bool, typeof(callback)}}})(G::Vector{Float64}, θ::Vector{Float64})\n",
      "    @ OptimizationOptimJL ~/anaconda3/envs/julia/share/julia/packages/OptimizationOptimJL/uRfW9/src/OptimizationOptimJL.jl:200\n",
      " [35] value_gradient!!(obj::TwiceDifferentiable{Float64, Vector{Float64}, Matrix{Float64}, Vector{Float64}}, x::Vector{Float64})\n",
      "    @ NLSolversBase ~/anaconda3/envs/julia/share/julia/packages/NLSolversBase/kavn7/src/interface.jl:82\n",
      " [36] initial_state(method::BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}, options::Optim.Options{Float64, OptimizationOptimJL.var\"#_cb#14\"{OptimizationOptimJL.OptimJLOptimizationCache{OptimizationFunction{false, Optimization.AutoZygote, OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.var\"#293#302\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#296#305\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#300#309\", Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}, Nothing, Nothing, Nothing, Nothing, Nothing, BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}, Base.Iterators.Cycle{Tuple{Optimization.NullData}}, Bool, typeof(callback)}}}, d::TwiceDifferentiable{Float64, Vector{Float64}, Matrix{Float64}, Vector{Float64}}, initial_x::Vector{Float64})\n",
      "    @ Optim ~/anaconda3/envs/julia/share/julia/packages/Optim/29per/src/multivariate/solvers/first_order/bfgs.jl:94\n",
      " [37] optimize(d::TwiceDifferentiable{Float64, Vector{Float64}, Matrix{Float64}, Vector{Float64}}, initial_x::Vector{Float64}, method::BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}, options::Optim.Options{Float64, OptimizationOptimJL.var\"#_cb#14\"{OptimizationOptimJL.OptimJLOptimizationCache{OptimizationFunction{false, Optimization.AutoZygote, OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.var\"#293#302\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#296#305\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#300#309\", Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}, Nothing, Nothing, Nothing, Nothing, Nothing, BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}, Base.Iterators.Cycle{Tuple{Optimization.NullData}}, Bool, typeof(callback)}}})\n",
      "    @ Optim ~/anaconda3/envs/julia/share/julia/packages/Optim/29per/src/multivariate/optimize/optimize.jl:36\n",
      " [38] __solve(cache::OptimizationOptimJL.OptimJLOptimizationCache{OptimizationFunction{false, Optimization.AutoZygote, OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.var\"#293#302\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#296#305\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#300#309\", Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}, Nothing, Nothing, Nothing, Nothing, Nothing, BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}, Base.Iterators.Cycle{Tuple{Optimization.NullData}}, Bool, typeof(callback)})\n",
      "    @ OptimizationOptimJL ~/anaconda3/envs/julia/share/julia/packages/OptimizationOptimJL/uRfW9/src/OptimizationOptimJL.jl:249\n",
      " [39] solve!(cache::OptimizationOptimJL.OptimJLOptimizationCache{OptimizationFunction{false, Optimization.AutoZygote, OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.var\"#293#302\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#296#305\"{Optimization.var\"#292#301\"{OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}}}, Optimization.var\"#300#309\", Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Optimization.ReInitCache{Vector{Float64}, SciMLBase.NullParameters}, Nothing, Nothing, Nothing, Nothing, Nothing, BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}, Base.Iterators.Cycle{Tuple{Optimization.NullData}}, Bool, typeof(callback)})\n",
      "    @ SciMLBase ~/anaconda3/envs/julia/share/julia/packages/SciMLBase/VdcHg/src/solve.jl:162\n",
      " [40] solve(::OptimizationProblem{true, OptimizationFunction{true, Optimization.AutoZygote, DiffEqFlux.var\"#121#128\"{var\"#tmp_loss#192\"{BitVector}}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}, Vector{Float64}, SciMLBase.NullParameters, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Base.Pairs{Symbol, Bool, Tuple{Symbol}, NamedTuple{(:allow_f_increases,), Tuple{Bool}}}}, ::BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}; kwargs::Base.Pairs{Symbol, Any, Tuple{Symbol, Symbol, Symbol}, NamedTuple{(:maxiters, :callback, :allow_f_increases), Tuple{Float64, typeof(callback), Bool}}})\n",
      "    @ SciMLBase ~/anaconda3/envs/julia/share/julia/packages/SciMLBase/VdcHg/src/solve.jl:83\n",
      " [41] sciml_train(::var\"#tmp_loss#192\"{BitVector}, ::Vector{Float64}, ::BFGS{InitialStatic{Float64}, BackTracking{Float64, Int64}, Nothing, Float64, Flat}, ::Nothing; lower_bounds::Nothing, upper_bounds::Nothing, cb::Function, callback::Function, maxiters::Float64, kwargs::Base.Pairs{Symbol, Bool, Tuple{Symbol}, NamedTuple{(:allow_f_increases,), Tuple{Bool}}})\n",
      "    @ DiffEqFlux ~/anaconda3/envs/julia/share/julia/packages/DiffEqFlux/Em1Aj/src/train.jl:43\n",
      " [42] top-level scope\n",
      "    @ ~/Escritorio/TFM/code/01_project/src/processing/experiments/schwarzschild/case_2/schwarzschild_train_n.ipynb:30"
     ]
    }
   ],
   "source": [
    "println(\"Begin Progressive training...\")\n",
    "\n",
    "num_optimization_increments = 100\n",
    "optimization_increments = [collect(40:10:num_optimization_increments-15)..., 85, 90, num_optimization_increments-5, num_optimization_increments-1,  num_optimization_increments]\n",
    "n = length(optimization_increments)\n",
    "epochs_increments = [100,100,100,100,100,100,100,100,100,150] / 10\n",
    "\n",
    "@assert length(epochs_increments) == length(optimization_increments)\n",
    "\n",
    "for (index, i) in enumerate(optimization_increments)\n",
    "\n",
    "    println(\"optimization increment :: \", i, \" of \", num_optimization_increments)\n",
    "    dataset[wave_ids[1]][\"tsteps\"]\n",
    "    tsteps_increment_bool = dataset[wave_ids[1]][\"tsteps\"] .<= dataset[wave_ids[1]][\"tspan\"][1] + i*(dataset[wave_ids[1]][\"tspan\"][2]-dataset[wave_ids[1]][\"tspan\"][1]) / num_optimization_increments\n",
    "    max_epochs = round(epochs_increments[index])\n",
    "    \n",
    "    println(\"Training \", max_epochs, \" epochs\")\n",
    "\n",
    "    tmp_loss(p) = loss_function_case2(\n",
    "        p, \n",
    "        tsteps_increment_bool=tsteps_increment_bool, \n",
    "        dataset_train=dataset_train, \n",
    "        dataset_test=dataset_test\n",
    "    )\n",
    "\n",
    "    # to learning rates / optimization algorithm to learn at different 'stages'\n",
    "    if index < n-3\n",
    "        # introduce randomness to avoid local minimum (not critical)\n",
    "        global NN_params = NN_params + Float64(1e-6)*randn(eltype(NN_params), size(NN_params)) #1e-7\n",
    "        local res = sciml_train(\n",
    "            tmp_loss, \n",
    "            NN_params,  \n",
    "            BFGS(initial_stepnorm=1e-1, linesearch = BackTracking()), \n",
    "            cb=callback, \n",
    "            maxiters = max_epochs, \n",
    "            allow_f_increases=true\n",
    "        )\n",
    "    else\n",
    "        # introduce randomness to avoid local minimum (not critical)\n",
    "        global NN_params = NN_params + Float64(1e-6)*randn(eltype(NN_params), size(NN_params))\n",
    "        local res = sciml_train(\n",
    "            tmp_loss,\n",
    "            NN_params, \n",
    "            BFGS(initial_stepnorm=2.5e-2, linesearch = BackTracking()), \n",
    "            cb=callback, \n",
    "            maxiters = max_epochs, \n",
    "            allow_f_increases=true\n",
    "        )\n",
    "    end\n",
    "    \n",
    "    global NN_params = res.minimizer\n",
    "end\n",
    "println(\"Finished training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>0×6 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">epochs</th><th style = \"text-align: left;\">test_name</th><th style = \"text-align: left;\">train_losses</th><th style = \"text-align: left;\">test_losses</th><th style = \"text-align: left;\">train_metric</th><th style = \"text-align: left;\">test_metric</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& epochs & test\\_name & train\\_losses & test\\_losses & train\\_metric & test\\_metric\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & Any & Any & Any & Any\\\\\n",
       "\t\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m0×6 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m epochs \u001b[0m\u001b[1m test_name \u001b[0m\u001b[1m train_losses \u001b[0m\u001b[1m test_losses \u001b[0m\u001b[1m train_metric \u001b[0m\u001b[1m test_metric\u001b[0m ⋯\n",
       "     │\u001b[90m Int64  \u001b[0m\u001b[90m String    \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any         \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any        \u001b[0m ⋯\n",
       "─────┴──────────────────────────────────────────────────────────────────────────"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "niter = range(1, length(train_losses))\n",
    "df_losses = DataFrame(\n",
    "    epochs=niter, \n",
    "    test_name=test_name, \n",
    "    train_losses = Float64.(train_losses_complete),\n",
    "    test_losses = Float64.(test_losses), \n",
    "    train_metric = Float64.(train_metrics_complete), \n",
    "    test_metric = Float64.(test_metrics)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: convert(::Type{Union{}}, ::Float64) is ambiguous. Candidates:\n  convert(::Type{C}, c::Number) where C<:Colorant in ColorTypes at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/ColorTypes/1dGw6/src/conversions.jl:74\n  convert(::Type{T}, x::Number) where T<:AbstractChar in Base at char.jl:184\n  convert(::Type{T}, x::Union{Bool, Float16, Float32, Float64, Int16, Int32, Int64, Int8, UInt16, UInt32, UInt64, UInt8, SIMDTypes.Bit}) where T<:VectorizationBase.AbstractSIMD in VectorizationBase at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/VectorizationBase/0dXyA/src/base_defs.jl:199\n  convert(::Type{T}, x::R) where {T<:ReverseDiff.TrackedReal, R<:Real} in ReverseDiff at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/ReverseDiff/Zu4v6/src/tracked.jl:263\n  convert(::Type{T}, x::Number) where T<:Number in Base at number.jl:7\n  convert(::Type{<:Measures.Measure}, x::Float64) in Plots.PlotMeasures at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/Plots/p3KMq/src/plotmeasures.jl:14\n  convert(::Type{Union{}}, x) in Base at essentials.jl:213\n  convert(::Type{P}, α) where P<:(MultivariatePolynomials.AbstractPolynomialLike) in MultivariatePolynomials at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/MultivariatePolynomials/sWAOE/src/conversion.jl:4\n  convert(::Type{T}, obj) where T<:FunctionWrappers.FunctionWrapper in FunctionWrappers at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/FunctionWrappers/Q5cBx/src/FunctionWrappers.jl:113\n  convert(::Type{T}, x) where T<:LabelledArrays.LArray in LabelledArrays at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/LabelledArrays/FI31L/src/larray.jl:143\n  convert(::Type{T}, arg) where T<:VecElement in Base at baseext.jl:19\nPossible fix, define\n  convert(::Type{Union{}}, ::Float64)",
     "output_type": "error",
     "traceback": [
      "MethodError: convert(::Type{Union{}}, ::Float64) is ambiguous. Candidates:\n",
      "  convert(::Type{C}, c::Number) where C<:Colorant in ColorTypes at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/ColorTypes/1dGw6/src/conversions.jl:74\n",
      "  convert(::Type{T}, x::Number) where T<:AbstractChar in Base at char.jl:184\n",
      "  convert(::Type{T}, x::Union{Bool, Float16, Float32, Float64, Int16, Int32, Int64, Int8, UInt16, UInt32, UInt64, UInt8, SIMDTypes.Bit}) where T<:VectorizationBase.AbstractSIMD in VectorizationBase at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/VectorizationBase/0dXyA/src/base_defs.jl:199\n",
      "  convert(::Type{T}, x::R) where {T<:ReverseDiff.TrackedReal, R<:Real} in ReverseDiff at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/ReverseDiff/Zu4v6/src/tracked.jl:263\n",
      "  convert(::Type{T}, x::Number) where T<:Number in Base at number.jl:7\n",
      "  convert(::Type{<:Measures.Measure}, x::Float64) in Plots.PlotMeasures at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/Plots/p3KMq/src/plotmeasures.jl:14\n",
      "  convert(::Type{Union{}}, x) in Base at essentials.jl:213\n",
      "  convert(::Type{P}, α) where P<:(MultivariatePolynomials.AbstractPolynomialLike) in MultivariatePolynomials at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/MultivariatePolynomials/sWAOE/src/conversion.jl:4\n",
      "  convert(::Type{T}, obj) where T<:FunctionWrappers.FunctionWrapper in FunctionWrappers at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/FunctionWrappers/Q5cBx/src/FunctionWrappers.jl:113\n",
      "  convert(::Type{T}, x) where T<:LabelledArrays.LArray in LabelledArrays at /home/rubenbalbastre/anaconda3/envs/julia/share/julia/packages/LabelledArrays/FI31L/src/larray.jl:143\n",
      "  convert(::Type{T}, arg) where T<:VecElement in Base at baseext.jl:19\n",
      "Possible fix, define\n",
      "  convert(::Type{Union{}}, ::Float64)\n",
      "\n",
      "Stacktrace:\n",
      "  [1] extrema(x::Vector{Union{}})\n",
      "    @ NaNMath ~/anaconda3/envs/julia/share/julia/packages/NaNMath/ceWIc/src/NaNMath.jl:180\n",
      "  [2] ignorenan_extrema(x::Vector{Union{}})\n",
      "    @ Plots ~/anaconda3/envs/julia/share/julia/packages/Plots/p3KMq/src/Plots.jl:138\n",
      "  [3] ignorenan_min_max(x::Vector{Union{}}, ex::Tuple{Float64, Float64})\n",
      "    @ Plots ~/anaconda3/envs/julia/share/julia/packages/Plots/p3KMq/src/utils.jl:89\n",
      "  [4] process_sliced_series_attributes!(plt::Plots.Plot{Plots.GRBackend}, kw_list::Vector{Dict{Symbol, Any}})\n",
      "    @ Plots ~/anaconda3/envs/julia/share/julia/packages/Plots/p3KMq/src/pipeline.jl:157\n",
      "  [5] _process_seriesrecipes!(plt::Any, kw_list::Any)\n",
      "    @ RecipesPipeline ~/anaconda3/envs/julia/share/julia/packages/RecipesPipeline/BGM3l/src/series_recipe.jl:16\n",
      "  [6] recipe_pipeline!(plt::Any, plotattributes::Any, args::Any)\n",
      "    @ RecipesPipeline ~/anaconda3/envs/julia/share/julia/packages/RecipesPipeline/BGM3l/src/RecipesPipeline.jl:99\n",
      "  [7] _plot!(plt::Plots.Plot, plotattributes::Any, args::Any)\n",
      "    @ Plots ~/anaconda3/envs/julia/share/julia/packages/Plots/p3KMq/src/plot.jl:223\n",
      "  [8] plot!(::Plots.Plot, ::Any, ::Vararg{Any}; kw::Base.Pairs{Symbol, V, Tuple{Vararg{Symbol, N}}, NamedTuple{names, T}} where {V, N, names, T<:Tuple{Vararg{Any, N}}})\n",
      "    @ Plots ~/anaconda3/envs/julia/share/julia/packages/Plots/p3KMq/src/plot.jl:213\n",
      "  [9] plot!(::Any, ::Vararg{Any}; kw::Base.Pairs{Symbol, V, Tuple{Vararg{Symbol, N}}, NamedTuple{names, T}} where {V, N, names, T<:Tuple{Vararg{Any, N}}})\n",
      "    @ Plots ~/anaconda3/envs/julia/share/julia/packages/Plots/p3KMq/src/plot.jl:202\n",
      " [10] top-level scope\n",
      "    @ ~/Escritorio/TFM/code/01_project/src/processing/experiments/schwarzschild/case_2/schwarzschild_train_n.ipynb:2"
     ]
    }
   ],
   "source": [
    "plot(df_losses[!, \"epochs\"], df_losses[!, \"train_losses\"], label=\"train\")\n",
    "plot!(losses_plot, df_losses[!, \"epochs\"], df_losses[!, \"test_losses\"], label=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: plot_list not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: plot_list not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Escritorio/TFM/code/01_project/src/processing/experiments/schwarzschild/case_2/schwarzschild_train_n.ipynb:1"
     ]
    }
   ],
   "source": [
    "plot(plot_list[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data\n"
     ]
    }
   ],
   "source": [
    "if save_data\n",
    "\n",
    "    println(\"Saving data\")\n",
    "\n",
    "    # naming dirs\n",
    "    solutions_dir = output_dir*\"solutions/\"\n",
    "    img_dir = output_dir*\"train_img_for_gif/\"\n",
    "    metrics_dir = output_directory*\"metrics/\"\n",
    "\n",
    "    # checking if directories exist\n",
    "    create_directory_if_does_not_exist(output_dir)\n",
    "    create_directory_if_does_not_exist(solutions_dir)\n",
    "    create_directory_if_does_not_exist(img_dir)\n",
    "    create_directory_if_does_not_exist(metrics_dir)\n",
    "\n",
    "    # save plots\n",
    "    if save_plots_gif\n",
    "        for (ind, img) in enumerate(plot_list)\n",
    "            savefig(img, img_dir*string(ind)*\"_train_img.png\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # save final plot\n",
    "    if show_plots\n",
    "        savefig(plot_list[end], output_dir*\"prediction_plot.png\")\n",
    "    end\n",
    "\n",
    "    if ! isfile(metrics_dir*\"losses.csv\")\n",
    "        CSV.write(metrics_dir*\"losses.csv\", df_losses)\n",
    "    else\n",
    "        x = DataFrame(CSV.File(metrics_dir*\"losses.csv\", types=Dict(\"test_name\" => String)))\n",
    "        append!(x, df_losses)\n",
    "        CSV.write(metrics_dir*\"losses.csv\", x)\n",
    "    end\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/JuliaIO/BSON.jl \n",
    "# https://stackoverflow.com/questions/66395998/saving-and-loading-model-and-the-best-weight-after-training-in-sciml-julia\n",
    "# save flux chain models as bson files. To do so, we must save chain model with its parameters\n",
    "NN_chiphi_params = NN_params[1:l1]\n",
    "NN_pe_params = NN_params[l1+1:end]\n",
    "Flux.loadparams!(chain_pe, Flux.params(re_pe(NN_pe_params)))\n",
    "Flux.loadparams!(chain_phichi, Flux.params(re_chiphi(NN_chiphi_params)))\n",
    "@save solutions_dir*\"model_chiphi.bson\" chain_phichi\n",
    "@save solutions_dir*\"model_pe.bson\" chain_pe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
